<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="digital public history in a global context #ias_nuq" />
  <title>the probable past</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="2025-06-10_IAS-NUQ_files/reveal.js-4.2.1/dist/reset.css">
  <link rel="stylesheet" href="2025-06-10_IAS-NUQ_files/reveal.js-4.2.1/dist/reveal.css">

  <style type="text/css">
    /* CSS from pandoc style.html() */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
                  </style>

  <link rel="stylesheet" href="2025-06-10_IAS-NUQ_files/reveal.js-4.2.1/dist/theme/simple.css" id="theme">


  <style type="text/css">
  /* some tweaks to reveal css */
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }
    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }
  </style>

    <script src="2025-06-10_IAS-NUQ_files/header-attrs-2.29/header-attrs.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">the probable past</h1>
  <h2 class="author">digital public history in a global context
#ias_nuq</h2>
  <h3 class="date">frédéric clavert / c²dh / <a
href="mailto:frederic.clavert@uni.lu">frederic.clavert@uni.lu</a></h3>
</section>

<section id="section" class="title-slide slide level1"
data-background="../img/darpa_bg.png">
<h1 data-background="../img/darpa_bg.png"></h1>
<p><a target=_blank href="https://www.tiktok.com/@gouvernementfr/video/7498659396088646934">POV:
you are a woman on April 29th [1945],<br /> and you are going to vote
for the first time</a></p>
<aside class="notes">
<p>This a video that the information service of the French Government
published on tik tok and instagram. It is obviously AI generated. the
aim was to commemorate the first time French women voted, in April
1945.</p>
<p>It was followed by another one, that intended to celebrate the role
of French women in the Resistance during the Second World War. At the
end of the video, a German soldier was celebrating Liberation with
French citizens, and one person in the video was holding a japanese
flag.</p>
<p>This seond video was removed within a fewx hours, after many
historians and citizens harshly criticized it on social media. Several
major and les major newspapers and newsmagazines published interviews
and op-ed of historians (including me) who did not only voiced criticism
against the content of the video, but also against the use of AI to
generate commemorative or historical artefacts.</p>
<p>And it is obvious that those videos are problematic in several
ways:</p>
<ul>
<li>the aestethic is bland,</li>
<li>the period’s distinctive features are standardized: all women have
the same clothing, the same faces, the same bikes,</li>
<li>there is no traces of war, whereas the war itself had not come yet
to an end (with still fightings in some French areas).</li>
</ul>
</aside>
</section>

<section id="why" class="title-slide slide level1">
<h1>why?</h1>
<aside class="notes">
<p>Why a State like France would produce such videos, whereas
relationship to the past is so important in this country? Whereas
archivists, librarians, historians, are often civil servants?</p>
<p>There are reasons that are specifically French – and among other
things the concurrence between several ministries and public
institutions when it comes to French memory politics, as well as the
current budgetary problems and government instability.</p>
<p>But let’s focus on something else: the core discourse of Generative
AI companies is hiding the fact that their chatbots are based on
language or diffusion models – they can predict the next word or the
next pixel, but are not supposed to be knowledge models.</p>
<p>Nevertheless, the dicourse of Gen AI companies is to make us believe
that those models are good to generate knowledge. That is visible in the
design of chatbots: the core of their interface are built around an
incentive to ask questions or text that will act as questions, with
answers that, in terms of design, are framed as answers with turstworthy
knowledge, trustworthy also because they are given with some ‘belle
langue’, well formulated language.</p>
<p>There is this idea, in this discourse, that you can access knowledge
thanks to a chatbot, without using some sort of traditional mediations
to knowledge and, hence, here to collective memory, so without
archivists, librarians, hisorians (wether professional or not) and
public historians, and even without more recent types of mediation such
as Wikipedia, for instance (though models were trained on the work of
all those).</p>
<p>This promise, within a French context in the case discussed here, is
making a point: you don’t need to ask those boring gate keepers such as
historians to reach out easily (or so is the intent) to younger people
for instance. This is an automation of intellectual work.</p>
</aside>
</section>

<section id="how" class="title-slide slide level1">
<h1>how?</h1>
<aside class="notes">
<p>But when we look at the ‘how’, we can realize that chatbots are
replacing traditional memory mediations (that I don’t consider perfect)
to a new sort of mediation. I define here chatbots in a quite broad way:
I include those which are easily generating videos, sounds, images,
texts, etc, as more and more chatbots are said to be multimodal, so can
handle at least text and images at the same type, as inputs and as
outputs. With Sora 2, this definition may evolve, by the way. At the
heart of those chatbots are models, whether language or diffusion
models. Of course, chatbots have aditional features, and additional
sorts of alignement, but I will focus on those models.</p>
<p>How do Generative AI models work? It’s basically machine learning: a
training dataset is used from which the machine learning algorithm is
deducing a set of probablistic relationsships between words or part of
words (tokens) or set of pixels (when generating images or videos).
Those probabilistic relationships (parameters) are together forming the
AI model.</p>
<p>This mediation is hence probabilistic. When we follow thie French
Female Citizen when she votes for the first time, we follow a sort of
probable past, not a past that actually happened. As historians, we do
not know everything about the past, there are holes in our knowledge,
and there will always be some holes. The advantage of a probable past is
that there’s no holes in the view on the past that is proposed by a
chatbot.</p>
</aside>
</section>

<section id="cost" class="title-slide slide level1">
<h1>cost</h1>
<aside class="notes">
<p>The price for such a probable past is very high.</p>
<p>Very high in terms of environment, very high in social terms. Because
the training phase is often not enough, there will be a reinforcement
feedback with human in the loop, a strange set of words that designates
digital labor, usually underpayed high-skilled workers from the global
south correcting some outputs of chatbots.</p>
<p>Another aspect of this price is datacolonialism: generative ai is
based on the appropriation of the data we are all generating on a daily
basis, when we use smartphones, computers and many other electronic
devices.</p>
<p>A last aspect of the price of generative AI is linked to the probable
past: it’s a change of regime of truth. Truth today is something
probable, and this probable truth depends on the training datasets of
generative AIs, datasets that have biases of very varied and different
natures. Datasets that are usually closed, that we cannot analyse
directly.</p>
</aside>
</section>

<section id="public-history-and-the-probable-past"
class="title-slide slide level1">
<h1>(public) history and the probable past</h1>
<aside class="notes">
<p>The thing is that the probable past might fit better the views on the
past of a government, whether French or not, whatever its political
nature. So the probable past is often an ideologically good enough
past.</p>
<p>So, we are in a very specific context, that is a mixture of the rise
of the generative ai chatbot, of rise of authoritarianism, of radical
undermining of international law, of rise of ‘technofascism’, an
ideology that basically exploits at its benefice this new regime of
truth. In this context, what can be the role of historians and public
historians?</p>
<p>I do not have a clear answer.</p>
<p>But:</p>
<ul>
<li>it cannot be ignorance. We cannot just ignore generative AI, we
cannot refuse to understand how it works, we cannot refuse to teach it
when necessary. In other words, and to get back to a discussion we had 2
days ago, generative AI will not destroy us neither save us. That’s not
the debate. We need to look precisely at what it does to our
relationship to the past, not be doomers – doom does not help to
think.</li>
<li>there are practices that already exists that should be emphasized.
Here I am specifically thinking about public history. The best incentive
to stimulate the abilities of our fellow citizens, of our students, of
ourselves, whatever the country we live in, to criticise any AI slop
generated about the past in our case, is to work together.</li>
<li>looking at our methodologies. Which one of them are underused today
but could be useful? I’m a text-based historian, and that is not enough,
we need to do more on images, moving or not, on sound, and on
documents.</li>
<li>we need to look at how we teach.</li>
</ul>
</aside>
</section>
    </div>
  </div>

  <script src="2025-06-10_IAS-NUQ_files/reveal.js-4.2.1/dist/reveal.js"></script>
  
  <!-- reveal.js plugins -->
  <script src="2025-06-10_IAS-NUQ_files/reveal.js-4.2.1/plugin/notes/notes.js"></script>
  
  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,
        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,
        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',
        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',
        // Display a presentation progress bar
        progress: true,
        // Can be used to limit the contexts in which the slide number appears
        showSlideNumber: 'all',
        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,
        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,
        // Push each slide change to the browser history
        // Implies `hash: true`
        history: true,
        // Enable keyboard shortcuts for navigation
        keyboard: true,
        // Enable the slide overview mode
        overview: true,
        // Vertical centering of slides
        center: true,
        // Enables touch navigation on devices with touch input
        touch: true,
        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',
        // Turns fragments on and off globally
        fragments: true,
        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,
        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,
        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,
        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,
        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,
        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,
        // Stop auto-sliding after user input
        autoSlideStoppable: true,
        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,
        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Transition style
        transition: 'convex', // none/fade/slide/convex/concave/zoom
        // Transition speed
        transitionSpeed: 'default', // default/fast/slow
        // Transition style for full page slide backgrounds
        backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom
        // Number of slides away from the current that are visible
        viewDistance: 3,
        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,
        // The display mode that will be used to show slides
        display: 'block',
        // Hide cursor if inactive
        hideInactiveCursor: true,
        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,



        // Optional reveal.js plugins
        plugins: [
          RevealNotes,
        ]
      });

    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
